{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jy4Ibc1PTX3d"
   },
   "source": [
    "# Fine-tuning Conditional Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:54:44.608663Z",
     "start_time": "2023-07-20T04:54:42.059097Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hNjQa8cTX3h",
    "outputId": "b0184617-b3cd-4caf-beb7-418cc1cb96df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.27.8)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (2022.6.15.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (1.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:54:50.688984Z",
     "start_time": "2023-07-20T04:54:47.392817Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (2022.6.15.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:54:54.701405Z",
     "start_time": "2023-07-20T04:54:53.508287Z"
    },
    "id": "63LX1YudU-3C"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import openai\n",
    "import signal\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "os.chdir(os.path.join(current_directory, '../TuningGPT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:54:58.924418Z",
     "start_time": "2023-07-20T04:54:58.915972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directly assign your API key if you prefer not to use a .txt file\n",
    "default_api_key = \"<your_api_key>\"\n",
    "\n",
    "# Or, specify the filename for the API key configuration\n",
    "config_filename = \"<api_key_file>.txt\"\n",
    "\n",
    "# Check if the <api_key_file>.txt file exists in the current directory\n",
    "if os.path.isfile(config_filename):\n",
    "    with open(config_filename, 'r') as file:\n",
    "        api_key = file.readline().strip().split('=')[1]\n",
    "else:\n",
    "    # Use the default API key if the file doesn't exist\n",
    "    api_key = default_api_key\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:55:02.177579Z",
     "start_time": "2023-07-20T04:55:02.139597Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbouxEafVdad",
    "outputId": "b4005c3a-714a-40e0-c1fb-8f79b2eb1ab5"
   },
   "outputs": [],
   "source": [
    "# Specify the .csv file with prompts and completions\n",
    "\n",
    "training_data = 'training_data.csv'\n",
    "\n",
    "def prepare_data(csv_file, jsonl_file):\n",
    "    training_data = []\n",
    "\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            prompt = row['prompt']\n",
    "            if not prompt.endswith('?'):\n",
    "                prompt += '?'  # Add question mark if missing\n",
    "            prompt = prompt + '->'\n",
    "            completion = ' ' + row['completion']\n",
    "            if not completion.endswith('.'):\n",
    "                completion += '.'  # Add period if missing\n",
    "            completion += '\\n'\n",
    "            entry = {'prompt': prompt,\n",
    "\t\t\t\t\t           'completion': completion}\n",
    "            training_data.append(entry)\n",
    "\n",
    "    with open(jsonl_file, 'w') as jsonlfile:\n",
    "        for entry in training_data:\n",
    "            json.dump(entry, jsonlfile)\n",
    "            jsonlfile.write('\\n')\n",
    "\n",
    "\n",
    "prepare_data(training_data, 'training_data.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOh4hao6WWLr",
    "outputId": "da10510f-76bc-49a1-99cf-70b65023ae2b"
   },
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"training_data.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:35:41.092631Z",
     "start_time": "2023-07-20T04:35:40.157609Z"
    },
    "id": "zuP2-34uVs1q"
   },
   "outputs": [],
   "source": [
    "training_file_id = openai.File.create(\n",
    "  file=open(\"training_data.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and sending a fine-tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhGWrfaUaT0G",
    "outputId": "7c69efad-a799-4ee9-e0b2-1e78ff15d4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ft-LTqFIfBcnJPH7QWQ6AbCnAhb.\n",
      "Training Response: {\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"id\": \"ft-LTqFIfBcnJPH7QWQ6AbCnAhb\",\n",
      "  \"hyperparams\": {\n",
      "    \"n_epochs\": 15,\n",
      "    \"batch_size\": 3,\n",
      "    \"prompt_loss_weight\": 0.01,\n",
      "    \"learning_rate_multiplier\": 0.3\n",
      "  },\n",
      "  \"organization_id\": \"org-RNi40Jk2y7io1td5Be2MNZms\",\n",
      "  \"model\": \"davinci\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"object\": \"file\",\n",
      "      \"id\": \"file-9aAWkUG1sdThMMDnmsjo5v3n\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"filename\": \"file\",\n",
      "      \"bytes\": 1318,\n",
      "      \"created_at\": 1689799566,\n",
      "      \"status\": \"uploaded\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"validation_files\": [],\n",
      "  \"result_files\": [],\n",
      "  \"created_at\": 1689799568,\n",
      "  \"updated_at\": 1689799568,\n",
      "  \"status\": \"pending\",\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-LTqFIfBcnJPH7QWQ6AbCnAhb\",\n",
      "      \"created_at\": 1689799568\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Training Status: pending\n"
     ]
    }
   ],
   "source": [
    "create_args = {\n",
    "\t\"training_file\": training_file_id,\n",
    "\t\"model\": \"davinci\",\n",
    "\t\"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "}\n",
    "\n",
    "response = openai.FineTune.create(**create_args)\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jwJsfqpaZWr",
    "outputId": "51c37b74-839e-4fb7-b0b4-5822e094cff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ft-LTqFIfBcnJPH7QWQ6AbCnAhb\n",
      "2023-07-19 20:46:08 Created fine-tune: ft-LTqFIfBcnJPH7QWQ6AbCnAhb\n",
      "Stream interrupted (client disconnected).\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "\tstatus = openai.FineTune.retrieve(job_id).status\n",
    "\tprint(f\"Stream interrupted. Job is still {status}.\")\n",
    "\treturn\n",
    "\n",
    "print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = openai.FineTune.stream_events(job_id)\n",
    "try:\n",
    "  for event in events:\n",
    "    print(f'{datetime.datetime.fromtimestamp(event[\"created_at\"])} {event[\"message\"]}')\n",
    "except Exception:\n",
    "  print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading existing fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:41:58.883727Z",
     "start_time": "2023-07-20T04:41:58.552670Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "uJ5i0yCjeP7r",
    "outputId": "33545935-3e6d-4846-c702-9e2e93a9ff18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune job ft-LTqFIfBcnJPH7QWQ6AbCnAhb finished with status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 4 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "  print(f'Job not in terminal status: {status}. Waiting.')\n",
    "  while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(2)\n",
    "    status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "    print(f'Status: {status}')\n",
    "else:\n",
    "  print(f'Finetune job {job_id} finished with status: {status}')\n",
    "\n",
    "\"\"\"\n",
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = openai.FineTune.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:42:18.883255Z",
     "start_time": "2023-07-20T04:42:18.750713Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "eG65uSHSgWpe",
    "outputId": "bad8440f-55bb-4063-e6de-68e1418594aa"
   },
   "outputs": [],
   "source": [
    "# openai.FineTune.retrieve(id=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:42:24.683538Z",
     "start_time": "2023-07-20T04:42:24.443821Z"
    },
    "id": "N4WweZUGdOSe"
   },
   "outputs": [],
   "source": [
    "fine_tuned_model = openai.FineTune.retrieve(id=job_id)[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending a prompt to a selected fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:44:18.900415Z",
     "start_time": "2023-07-20T04:44:17.142961Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt4mGJpHcia9",
    "outputId": "3fc91b65-3784-4648-9b65-f941edd37da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> The smallest bone in the entire human body is the hyoid bone.\n",
      "\n",
      "-> The type of gas utilized by plants during the process of photosynthesis is oxygen\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"Which part is the smallest bone in the entire human body?\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer['choices'][0]['text'])\n",
    "\n",
    "new_prompt = \"\"\" Which type of gas is utilized by plants during the process of photosynthesis?\"\"\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer['choices'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
