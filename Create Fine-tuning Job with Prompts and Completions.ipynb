{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jy4Ibc1PTX3d"
   },
   "source": [
    "# Fine-tuning Conditional Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:54:44.608663Z",
     "start_time": "2023-07-20T04:54:42.059097Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hNjQa8cTX3h",
    "outputId": "b0184617-b3cd-4caf-beb7-418cc1cb96df"
   },
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install PyPDF2\n",
    "!pip install openai chromadb\n",
    "!pip install tiktoken\n",
    "!pip install python-pptx\n",
    "!pip install pathlib\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:54:50.688984Z",
     "start_time": "2023-07-20T04:54:47.392817Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import openai\n",
    "import signal\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import langchain\n",
    "import PyPDF2\n",
    "from pptx import Presentation\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "os.chdir(os.path.join(current_directory, '../TuningGPT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:54:58.924418Z",
     "start_time": "2023-07-20T04:54:58.915972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directly assign your API key if you prefer not to use a .txt file\n",
    "default_api_key = \"<your_api_key>\"\n",
    "\n",
    "# Or, specify the filename for the API key configuration\n",
    "config_filename = \"<api_key_file>.txt\"\n",
    "\n",
    "# Check if the <api_key_file>.txt file exists in the current directory\n",
    "if os.path.isfile(config_filename):\n",
    "    with open(config_filename, 'r') as file:\n",
    "        api_key = file.readline().strip().split('=')[1]\n",
    "else:\n",
    "    # Use the default API key if the file doesn't exist\n",
    "    api_key = default_api_key\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:55:02.177579Z",
     "start_time": "2023-07-20T04:55:02.139597Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbouxEafVdad",
    "outputId": "b4005c3a-714a-40e0-c1fb-8f79b2eb1ab5"
   },
   "outputs": [],
   "source": [
    "# Specify the .csv file with prompts and completions\n",
    "\n",
    "training_data = 'training_data.csv'\n",
    "\n",
    "def prepare_data(csv_file, jsonl_file):\n",
    "    training_data = []\n",
    "\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            prompt = row['prompt']\n",
    "            prompt = prompt.lower()   # Convert all prompts to lowercase\n",
    "            if not prompt.endswith('?'):\n",
    "                prompt += '?'  # Add question mark if missing\n",
    "            prompt = prompt + '->'\n",
    "            completion = ' ' + row['completion']\n",
    "            if not completion.endswith('.'):\n",
    "                completion += '.'  # Add period if missing\n",
    "            completion += '\\n'\n",
    "            entry = {'prompt': prompt,\n",
    "\t\t\t\t\t           'completion': completion}\n",
    "            training_data.append(entry)\n",
    "\n",
    "    with open(jsonl_file, 'w') as jsonlfile:\n",
    "        for entry in training_data:\n",
    "            json.dump(entry, jsonlfile)\n",
    "            jsonlfile.write('\\n')\n",
    "\n",
    "\n",
    "prepare_data(training_data, 'training_data.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOh4hao6WWLr",
    "outputId": "da10510f-76bc-49a1-99cf-70b65023ae2b"
   },
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"training_data.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:35:41.092631Z",
     "start_time": "2023-07-20T04:35:40.157609Z"
    },
    "id": "zuP2-34uVs1q"
   },
   "outputs": [],
   "source": [
    "training_file_id = openai.File.create(\n",
    "  file=open(\"training_data.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Sending a Fine-tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhGWrfaUaT0G",
    "outputId": "7c69efad-a799-4ee9-e0b2-1e78ff15d4ec"
   },
   "outputs": [],
   "source": [
    "create_args = {\n",
    "\t\"training_file\": training_file_id,\n",
    "\t\"model\": \"davinci\",\n",
    "\t\"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "}\n",
    "\n",
    "response = openai.FineTune.create(**create_args)\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jwJsfqpaZWr",
    "outputId": "51c37b74-839e-4fb7-b0b4-5822e094cff1"
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "\tstatus = openai.FineTune.retrieve(job_id).status\n",
    "\tprint(f\"Stream interrupted. Job is still {status}.\")\n",
    "\treturn\n",
    "\n",
    "print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = openai.FineTune.stream_events(job_id)\n",
    "try:\n",
    "  for event in events:\n",
    "    print(f'{datetime.datetime.fromtimestamp(event[\"created_at\"])} {event[\"message\"]}')\n",
    "except Exception:\n",
    "  print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:41:58.883727Z",
     "start_time": "2023-07-20T04:41:58.552670Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "uJ5i0yCjeP7r",
    "outputId": "33545935-3e6d-4846-c702-9e2e93a9ff18"
   },
   "outputs": [],
   "source": [
    "# Check fine-tuning Status\n",
    "\n",
    "import time\n",
    "\n",
    "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "  print(f'Job not in terminal status: {status}. Waiting.')\n",
    "  while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(2)\n",
    "    status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "    print(f'Status: {status}')\n",
    "else:\n",
    "  print(f'Finetune job {job_id} finished with status: {status}')\n",
    "\n",
    "\"\"\"\n",
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = openai.FineTune.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:42:18.883255Z",
     "start_time": "2023-07-20T04:42:18.750713Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "eG65uSHSgWpe",
    "outputId": "bad8440f-55bb-4063-e6de-68e1418594aa"
   },
   "outputs": [],
   "source": [
    "# Retrieve fine-tunning job information\n",
    " \n",
    "openai.FineTune.retrieve(id=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, fill in job_id manually if session expires\n",
    "#job_id = '<fine_tunning_job_id>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:42:24.683538Z",
     "start_time": "2023-07-20T04:42:24.443821Z"
    },
    "id": "N4WweZUGdOSe"
   },
   "outputs": [],
   "source": [
    "fine_tuned_model = openai.FineTune.retrieve(id=job_id)[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, fill in model manually if it is obtained from Postman\n",
    "#fine_tuned_model = \"<fine_tunned_model_id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending a Prompt to a Selected Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T04:44:18.900415Z",
     "start_time": "2023-07-20T04:44:17.142961Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt4mGJpHcia9",
    "outputId": "3fc91b65-3784-4648-9b65-f941edd37da4"
   },
   "outputs": [],
   "source": [
    "# Add stop=[\".\\n\"] to make sure the response ends at proper location\n",
    "# Add max_tokens to avoid incomplete answers\n",
    "\n",
    "new_prompt = \"What is the name of the course?\"\n",
    "new_prompt = new_prompt.lower()\n",
    "\n",
    "if not new_prompt.endswith('?'):\n",
    "        new_prompt += '?'  # Add question mark if missing\n",
    "new_prompt = new_prompt + '->'\n",
    "\n",
    "\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt,\n",
    "  stop=[\".\\n\"],\n",
    "  best_of = 10,\n",
    "  max_tokens = 1000\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = answer['choices'][0]['text']\n",
    "if (not generated_text.endswith('.')) or (not generated_text.endswith('. ')):\n",
    "    generated_text += '.'\n",
    "\n",
    "print(generated_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    responses = []\n",
    "    for index, row in df.iterrows():\n",
    "        prompt = row[\"prompt\"]\n",
    "        prompt = prompt.lower()\n",
    "        \n",
    "        if not prompt.endswith('?'):\n",
    "                prompt += '?'  # Add question mark if missing\n",
    "        prompt = prompt + '->'\n",
    "\n",
    "        answer = openai.Completion.create(\n",
    "          model=fine_tuned_model,\n",
    "          prompt=prompt,\n",
    "          stop=[\".\\n\"],\n",
    "          best_of = 10,\n",
    "          max_tokens = 100\n",
    "        )\n",
    "\n",
    "        generated_text = answer['choices'][0]['text']\n",
    "        if (not generated_text.endswith('.')) and (not generated_text.endswith('. ')):\n",
    "            generated_text += '.'\n",
    "\n",
    "        responses.append(generated_text)\n",
    "    return responses\n",
    "\n",
    "file_path = \"/content/drive/MyDrive/Research/TuningGPT/test_SameQuestion.csv\"\n",
    "responses = process_dataframe(file_path)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Make sure the number of items in the list matches the number of rows in the DataFrame\n",
    "if len(responses) != len(df):\n",
    "    print(\"Number of responses doesn't match the number of rows in the file.\")\n",
    "else:\n",
    "    # Fill in the \"response\" column\n",
    "    for i, response in enumerate(responses):\n",
    "        df.at[i, \"response\"] = response\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "    print(\"Responses successfully filled in the file.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
